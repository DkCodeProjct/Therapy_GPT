{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10250872,"sourceType":"datasetVersion","datasetId":6340458}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nbatchsiz = 64\nblocksiz = 128\nepochs = 700\nevalIntervals = 100\nlr = 3e-4\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nevaliters = 200\nnemb = 158\nnhead = 4\nnlayers = 4\ndropout = 0.2\n\n\nwith open('/kaggle/input/200232823/train.csv', 'r', encoding='utf-8') as f:\n    txt = f.read()\n\n# Initialize tokenizer\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n\ndef enc(txt, tokenizer):\n    tokens = tokenizer(txt, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n    return tokens.flatten()\n\ndata = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n\nn = int(0.9 * len(data))  # First 90% for training, last 10% for validation\ntrainData = data[:n]\nvalData = data[n:]\n\nprint(f\"Training data size: {trainData.size(0)}\")\nprint(f\"Validation data size: {valData.size(0)}\")\n\n\nvocabsiz = len(tokenizer)\nprint(\"vocab siz: \", vocabsiz)\n\n\ndef getBatch(split, block_size=128, batch_size=32):\n    dataset = trainData if split == \"train\" else valData\n    ix = torch.randint(0, len(dataset) - block_size, (batch_size,))\n\n    x = torch.stack([dataset[i:i + block_size] for i in ix])  # Inputs\n    y = torch.stack([dataset[i + 1:i + block_size + 1] for i in ix])  # Targets\n    x, y = x.to(device), y.to(device)\n\n    return x, y\n\n\n\n@torch.no_grad()\ndef estimateLoss():\n    out = { }\n    model.eval()\n    for split in [\"train\", \"val\"]:\n        losses = torch.zeros(evaliters)\n        for k in range(evaliters):\n            X, Y = getBatch(split)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n\n    model.train()\n    return out\n\nclass Head(nn.Module):\n    def __init__(self, headsiz):\n        super().__init__()\n        self.key = nn.Linear(nemb, headsiz, bias=False)\n        self.quary = nn.Linear(nemb, headsiz, bias=False)\n        self.value = nn.Linear(nemb, headsiz, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n        self.register_buffer(\"tril\", torch.tril(torch.ones(blocksiz, blocksiz)))\n\n    def forward(self, x):\n        B, T, C = x.shape\n        k = self.key(x)\n        q = self.quary(x)\n\n        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n        w = w.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n        w = F.softmax(w, dim=-1)\n        w = self.dropout(w)\n\n        v = self.value(x)\n\n        out = w @ v\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, nhead, headsiz):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(headsiz) for _ in range(nhead)])\n        self.proj = nn.Linear(headsiz * nhead, nemb)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n\n        return out\n\nclass FeedForwardNetwork(nn.Module):\n    def __init__(self, nemb):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(nemb, 4 * nemb),\n            nn.ReLU(),\n            nn.Linear(4 * nemb, nemb),\n            nn.Dropout(dropout)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    def __init__(self, nemb, nhead):\n        super().__init__()\n        headsiz =  nemb // nhead\n        self.selfattn = MultiHeadAttention(nhead, headsiz)\n        self.ffn = FeedForwardNetwork(nemb)\n        self.ln_1 = nn.LayerNorm(nemb)\n        self.ln_2 = nn.LayerNorm(nemb)\n\n    def forward(self, x):\n        x = x + self.selfattn(self.ln_1(x))\n        x = x + self.ffn(self.ln_2(x))\n\n        return x\n\nclass GPTLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocabsiz, nemb)\n        self.wpe = nn.Embedding(blocksiz, nemb)\n        self.block = nn.Sequential(*[Block(nemb, nhead=nhead) for _ in range(nlayers)])\n        self.ln_finl = nn.LayerNorm(nemb)\n        self.lm_head = nn.Linear(nemb, vocabsiz)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, ix, targt=None):\n        B, T = ix.shape\n\n        tokEmb = self.wte(ix)\n        posEmb = self.wpe(torch.arange(T, device=device))\n        x = tokEmb + posEmb\n        x = self.block(x)\n        x = self.ln_finl(x)\n\n        logits = self.lm_head(x)\n\n        if targt is None:\n            loss = None\n\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targt = targt.view(B*T)\n            loss = F.cross_entropy(logits, targt)\n\n        return logits, loss\n    def generate(self, idx, max_new_tokens, tokenizer):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last block_size tokens\n            idx_cond = idx[:, -blocksiz:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :]  # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1)  # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n\n        # Decode the generated token indices to text\n        generated_text = tokenizer.decode(idx[0].cpu().numpy().tolist(), skip_special_tokens=True)\n        return generated_text\n\nmodel = GPTLanguageModel()\nm = model.to(device)\n# Use Torch.Compinle,, well Expect that fucking Error\nuseCompile = False\nif useCompile:\n    model = torch.compile(model)\noptim = torch.optim.AdamW(model.parameters(), lr=lr)\n\noptim = torch.optim.AdamW(model.parameters(), lr=lr)\n\nlossi = []\nfor i in range(epochs):\n    if i % evalIntervals == 0 or i == epochs - 1:\n        losses = estimateLoss()\n        lossi.append(losses[\"val\"].item())\n        print(f\"Step {i} | train loss {losses['train']:.4f} | val loss {losses['val']:.4f}\")\n\n    xb, yb = getBatch(\"train\")\n    logits, loss = model(xb, yb)\n\n    optim.zero_grad()\n    loss.backward()\n    optim.step()\n\n\ndef saveCheckpnt(model, optimizer, epoch, loss, filepath):\n    checkPnt = {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"epoch\": epoch,\n        \"loss\": loss,\n    }\n    torch.save(checkPnt, filepath)\n    print(f\"Checkpoint saved to {filepath}\")\n\n# Saving model checkpoint\nsaveCheckpnt(model, optim, epochs-1, lossi[-1], \"TherapyModelTrainFinl.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T04:52:57.273231Z","iopub.execute_input":"2024-12-20T04:52:57.273634Z","iopub.status.idle":"2024-12-20T04:56:59.029311Z","shell.execute_reply.started":"2024-12-20T04:52:57.273599Z","shell.execute_reply":"2024-12-20T04:56:59.028507Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-f30568a21bf9>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n","output_type":"stream"},{"name":"stdout","text":"Training data size: 1843\nValidation data size: 205\nvocab siz:  49152\nStep 0 | train loss 10.8293 | val loss 10.8543\nStep 100 | train loss 4.1428 | val loss 4.8971\nStep 200 | train loss 1.3494 | val loss 3.5188\nStep 300 | train loss 0.3244 | val loss 3.5315\nStep 400 | train loss 0.1190 | val loss 3.7224\nStep 500 | train loss 0.0673 | val loss 3.7361\nStep 600 | train loss 0.0504 | val loss 3.8606\nStep 699 | train loss 0.0407 | val loss 3.9559\nCheckpoint saved to TherapyModelTrainFinl.pth\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Genarate From the Pre-Trained MODEL\n","metadata":{}},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)  # Initial context\ngenTxt = model.generate(context, max_new_tokens=500, tokenizer=tokenizer)\n\nprint(genTxt) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T04:57:25.835857Z","iopub.execute_input":"2024-12-20T04:57:25.836193Z","iopub.status.idle":"2024-12-20T04:57:37.817502Z","shell.execute_reply.started":"2024-12-20T04:57:25.836163Z","shell.execute_reply":"2024-12-20T04:57:37.816687Z"}},"outputs":[{"name":"stdout","text":" that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that\n\"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n   How can I change my feeling of being worthless to everyone?\",\"That is present; and to reach out'm worthless with my client to work with my issues with strengthening  self esteem, by guiding my client with CBT practices. CBT practices. CBT helps with gaining a better awareness of how your thought process influences your belief system, and how your beliefs impact your actions and the outcome of your behaviors.  This process isn’t relationships, stress, self esteem, codependency, etc.\"\n\"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n   How can I change my feeling of being worthless to everyone?\",\"Therapy is essential for those that are feeling depressed and worthless. When I work with those that are experiencing concerns related to feeling of depression and issues with self esteem. allow you to take it's ACS life by being worthless. When I work with those that are exhibiting some specific traits of a particular temperament type. Seek out a counselor who provides NCC\"\n\"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n   How can I change my feeling of being worthless to everyone?\",You are exhibiting some specific traits of a particular temperament type. Seek out a counselor who provides NCCA temperament therapy and discover the joy of being you Rural'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I've never tried or contemplated suicide. I\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Fine Tune The Model..","metadata":{}},{"cell_type":"code","source":"\n################\n##############\n###\n##   FINE TUNE THE MODEL\n###\n##############\n################\n\n# Load the tokenizer\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n\n# Define parameters\nbatch_size = 64\nblock_size = 128\nepochs = 40  # Fewer epochs for fine-tuning\nlr = 1e-5  # Lower learning rate for fine-tuning\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load your pre-trained model\ncheckpoint_path = \"TherapyModelTrainFinl.pth\"\nmodel = GPTLanguageModel()\nmodel.load_state_dict(torch.load(checkpoint_path, map_location=device)[\"model_state_dict\"])\nmodel = model.to(device)\n\n# Load the fine-tuning dataset\nwith open('/kaggle/input/200232823/finetune_train.csv', 'r', encoding='utf-8') as f:\n    fine_tune_text = f.read()\n\n# Tokenize the fine-tuning data\ndef encode_text(text, tokenizer):\n    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n    return tokens.flatten()\n\nfine_tune_data = encode_text(fine_tune_text, tokenizer)\n\n# Split the data into training and validation sets\nn = int(0.9 * len(fine_tune_data))  # 90% train, 10% validation\ntrain_data = fine_tune_data[:n]\nval_data = fine_tune_data[n:]\n\n# Function to create batches\ndef get_batch(split, block_size=128, batch_size=32):\n    dataset = train_data if split == \"train\" else val_data\n    ix = torch.randint(0, len(dataset) - block_size, (batch_size,))\n    x = torch.stack([dataset[i:i + block_size] for i in ix])\n    y = torch.stack([dataset[i + 1:i + block_size + 1] for i in ix])\n    x, y = x.to(device), y.to(device)\n    return x, y\n\n# Fine-tune the model\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n\nfor epoch in range(epochs):\n    model.train()\n    for _ in range(len(train_data) // batch_size):\n        xb, yb = get_batch(\"train\")\n        logits, loss = model(xb, yb)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # Validation loss\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for _ in range(len(val_data) // batch_size):\n            xb, yb = get_batch(\"val\")\n            _, loss = model(xb, yb)\n            val_loss += loss.item()\n    val_loss /= (len(val_data) // batch_size)\n    print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss:.4f}\")\n\n# Save the fine-tuned model\ntorch.save(model.state_dict(), \"TherapyModelFineTuned.pth\")\nprint(\"Fine-tuning complete. Model saved as TherapyModelFineTuned.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T05:04:47.361323Z","iopub.execute_input":"2024-12-20T05:04:47.361669Z","iopub.status.idle":"2024-12-20T05:07:38.613244Z","shell.execute_reply.started":"2024-12-20T05:04:47.361640Z","shell.execute_reply":"2024-12-20T05:07:38.612171Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-6-6a40034c7658>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(checkpoint_path, map_location=device)[\"model_state_dict\"])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Validation Loss: 4.6347\nEpoch 2, Validation Loss: 4.4912\nEpoch 3, Validation Loss: 4.5746\nEpoch 4, Validation Loss: 4.4782\nEpoch 5, Validation Loss: 4.3949\nEpoch 6, Validation Loss: 4.5260\nEpoch 7, Validation Loss: 4.4914\nEpoch 8, Validation Loss: 4.5722\nEpoch 9, Validation Loss: 4.5415\nEpoch 10, Validation Loss: 4.4911\nEpoch 11, Validation Loss: 4.5734\nEpoch 12, Validation Loss: 4.5097\nEpoch 13, Validation Loss: 4.5150\nEpoch 14, Validation Loss: 4.3287\nEpoch 15, Validation Loss: 4.3545\nEpoch 16, Validation Loss: 4.5533\nEpoch 17, Validation Loss: 4.4574\nEpoch 18, Validation Loss: 4.4209\nEpoch 19, Validation Loss: 4.6485\nEpoch 20, Validation Loss: 4.4906\nEpoch 21, Validation Loss: 4.4939\nEpoch 22, Validation Loss: 4.4101\nEpoch 23, Validation Loss: 4.4335\nEpoch 24, Validation Loss: 4.3816\nEpoch 25, Validation Loss: 4.5584\nEpoch 26, Validation Loss: 4.3650\nEpoch 27, Validation Loss: 4.4761\nEpoch 28, Validation Loss: 4.5086\nEpoch 29, Validation Loss: 4.4997\nEpoch 30, Validation Loss: 4.5644\nEpoch 31, Validation Loss: 4.4223\nEpoch 32, Validation Loss: 4.4477\nEpoch 33, Validation Loss: 4.5629\nEpoch 34, Validation Loss: 4.5172\nEpoch 35, Validation Loss: 4.5047\nEpoch 36, Validation Loss: 4.4337\nEpoch 37, Validation Loss: 4.3625\nEpoch 38, Validation Loss: 4.5638\nEpoch 39, Validation Loss: 4.5380\nEpoch 40, Validation Loss: 4.4441\nFine-tuning complete. Model saved as TherapyModelFineTuned.pth\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Chat With The Model..\n * after 10 epoch of fine-tune","metadata":{}},{"cell_type":"code","source":"\n# Chat with the fine-tuned model\ndef chat_with_model(prompt, model, tokenizer, max_new_tokens=50):\n    model.eval()\n    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n    with torch.no_grad():\n        generated_text = model.generate(input_ids, max_new_tokens, tokenizer)\n    return generated_text\n\n# Example chat\nwhile True:\n    prompt = input(\"You: \")\n    if prompt.lower() in [\"exit\", \"quit\"]:\n        break\n    response = chat_with_model(prompt, model, tokenizer)\n    print(f\"Model: {response}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T04:59:35.565945Z","iopub.execute_input":"2024-12-20T04:59:35.566231Z","iopub.status.idle":"2024-12-20T05:04:29.103064Z","shell.execute_reply.started":"2024-12-20T04:59:35.566209Z","shell.execute_reply":"2024-12-20T05:04:29.102198Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"You:  i feel anxious, and i don't know how to deal with it\n"},{"name":"stdout","text":"Model: i feel anxious, and i don't know how to deal with it.\n   How can I change my feeling of being worthless to everyone?\",First thing I'd suggest is getting the sleep you need or it will impact how you think and feel. I'd look at finding what just pop in your life and what you can\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  hi, how are you\n"},{"name":"stdout","text":"Model: hi, how are you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  how can i deal with my anxiety\n"},{"name":"stdout","text":"Model: how can i deal with my anxiety, stress, self esteem, codependency, etc.\"\n\" neurushed'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  who are you?\n"},{"name":"stdout","text":"Model: who are you?\",\" watch out for this, it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another sign of a worsening depression. The new thought\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  how to deal with panic atacks\n"},{"name":"stdout","text":"Model: how to deal with panic atacks to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  why i fell i'm worthless.\n"},{"name":"stdout","text":"Model: why i fell i'm worthless. When I work with those that are experiencing concerns related to feeling of depression and issues with self esteem suicidal thoughts Collaborative generally work with my client to help build coping skills to reduce level of depression and to assist with strengthening  self esteem, by guiding my\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  hi\n"},{"name":"stdout","text":"Model: hi even self-273-8255. The text line is #741741. I hope some other colleagues will provide you more suggestions. Be well...Robin Landwehr, DBH, LP\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"}],"execution_count":5},{"cell_type":"markdown","source":"# Chat with the Model after 40 Epoch of Fine-tune","metadata":{}},{"cell_type":"code","source":"\n# Chat with the fine-tuned model\ndef chat_with_model(prompt, model, tokenizer, max_new_tokens=50):\n    model.eval()\n    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n    with torch.no_grad():\n        generated_text = model.generate(input_ids, max_new_tokens, tokenizer)\n    return generated_text\n\n# Example chat\nwhile True:\n    prompt = input(\"You: \")\n    if prompt.lower() in [\"exit\", \"quit\"]:\n        break\n    response = chat_with_model(prompt, model, tokenizer)\n    print(f\"Model: {response}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T05:07:56.440935Z","iopub.execute_input":"2024-12-20T05:07:56.441219Z","iopub.status.idle":"2024-12-20T05:11:57.260495Z","shell.execute_reply.started":"2024-12-20T05:07:56.441197Z","shell.execute_reply":"2024-12-20T05:11:57.259528Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  hi, how are you\n"},{"name":"stdout","text":"Model: hi, how are you as you are!\n\" springtimelessness is unfortunately common. In fact, if not all, have felt this’t easy but many people, have felt this to some degree at some point in their life. You are not alone. Changing our\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  i feel anxious how can i deal with it\n"},{"name":"stdout","text":"Model: i feel anxious how can i deal with it helps teach an individual that we don’t always have control over what happens in our lives but we can esteem, codependency, etc.\"\n\"ower executives process isn’t always have control how we interpret, toxic relationships, etc.\"\n\"\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  why i feel very unfulfilled \n"},{"name":"stdout","text":"Model: why i feel very unfulfilled  As for different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  how can i calm my mind.\n"},{"name":"stdout","text":"Model: how can i calm my mind. Seek out a counselor who provides NCC Butterflyshire with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I've never tried or contemplated suicide. I've always\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  iv'e attempt to suicide.\n"},{"name":"stdout","text":"Model: iv'e attempt to suicide. I've always wanted to fix my issues, but I never get around to it.\n   How can I change my feeling of being worthless to everyone?\",\" stress, self esteemerally applied.\"\n\"Typ once they learn how to manage the ones they\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  what is your name\n"},{"name":"stdout","text":"Model: what is your name another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  ok thank you\n"},{"name":"stdout","text":"Model: ok thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone. Changing our feelings is\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}